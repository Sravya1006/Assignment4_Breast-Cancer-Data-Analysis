{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model, scaler, and selector\n",
    "# This block is essential for deploying the trained model in a production environment or for further testing\n",
    "with open('breast_cancer_model.pkl', 'rb') as model_file:\n",
    "    mlp = pickle.load(model_file)  # Load the trained MLP model\n",
    "\n",
    "with open('scaler.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)  # Load the scaler for data normalization\n",
    "\n",
    "with open('selector.pkl', 'rb') as selector_file:\n",
    "    selector = pickle.load(selector_file)  # Load the selector for feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the breast cancer dataset\n",
    "# This step simulates loading new data for prediction in a real-world scenario\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target  # Include target to verify our predictions if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new sample for prediction using a dictionary\n",
    "# This represents how new data might come in, typically in a form that needs to be preprocessed like the training data\n",
    "input_data = {\n",
    "    'mean radius': [17.99],\n",
    "    'mean texture': [10.38],\n",
    "    'mean perimeter': [122.80],\n",
    "    'mean area': [1001.0],\n",
    "    'mean smoothness': [0.11840],\n",
    "    'mean compactness': [0.27760],\n",
    "    'mean concavity': [0.3001],\n",
    "    'mean concave points': [0.14710],\n",
    "    'mean symmetry': [0.2419],\n",
    "    'mean fractal dimension': [0.07871],\n",
    "    'radius error': [1.095],\n",
    "    'texture error': [0.9053],\n",
    "    'perimeter error': [8.589],\n",
    "    'area error': [153.40],\n",
    "    'smoothness error': [0.00663],\n",
    "    'compactness error': [0.04954],\n",
    "    'concavity error': [0.05373],\n",
    "    'concave points error': [0.01587],\n",
    "    'symmetry error': [0.03003],\n",
    "    'fractal dimension error': [0.00268],\n",
    "    'worst radius': [25.38],\n",
    "    'worst texture': [17.33],\n",
    "    'worst perimeter': [184.60],\n",
    "    'worst area': [2019.0],\n",
    "    'worst smoothness': [0.1622],\n",
    "    'worst compactness': [0.6656],\n",
    "    'worst concavity': [0.7119],\n",
    "    'worst concave points': [0.2654],\n",
    "    'worst symmetry': [0.4601],\n",
    "    'worst fractal dimension': [0.11890]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame to facilitate scaling and feature selection\n",
    "input_df = pd.DataFrame(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the input data using the saved scaler and selector\n",
    "# This step is crucial to ensure that the data fed into the model is in the same format as the data used for training\n",
    "input_data_scaled = scaler.transform(input_df)\n",
    "input_data_selected = selector.transform(input_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the trained model\n",
    "# Here we predict both the class and the probability of the class to provide more detailed output\n",
    "prediction = mlp.predict(input_data_selected)\n",
    "prediction_proba = mlp.predict_proba(input_data_selected)[0][1]  # Probability of being malignant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new sample: Benign\n",
      "Probability of being malignant: 0.0027\n"
     ]
    }
   ],
   "source": [
    "# Print the result, converting binary prediction to a human-readable format\n",
    "result = \"Malignant\" if prediction[0] == 1 else \"Benign\"\n",
    "print(f\"Prediction for the new sample: {result}\")\n",
    "print(f\"Probability of being malignant: {prediction_proba:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
